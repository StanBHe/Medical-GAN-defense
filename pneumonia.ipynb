{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c3c02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\stan\\anaconda3\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\stan\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d09d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F \n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn,optim\n",
    "from torchvision import transforms,datasets,models\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "from torch import nn, optim\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3bfb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "        transforms.Resize(255),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "        transforms.Resize(255),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "transformer = {\n",
    "    'dataset1': transforms.Compose([transforms.Resize(255),\n",
    "                                            transforms.CenterCrop(224),\n",
    "                                            transforms.RandomHorizontalFlip(),\n",
    "                                            transforms.RandomRotation(10),\n",
    "                                            transforms.RandomGrayscale(),\n",
    "                                            transforms.RandomAffine(translate=(0.05,0.05), degrees=0),\n",
    "                                            transforms.ToTensor()\n",
    "                                           ]),\n",
    "    \n",
    "    'dataset2' : transforms.Compose([transforms.Resize(255),\n",
    "                                            transforms.CenterCrop(224),\n",
    "                                            transforms.RandomHorizontalFlip(p=1),\n",
    "                                            transforms.RandomGrayscale(),\n",
    "                                            transforms.RandomAffine(translate=(0.1,0.05), degrees=10),\n",
    "                                            transforms.ToTensor()\n",
    "                                    \n",
    "                                           ]),\n",
    "    'dataset3' : transforms.Compose([transforms.Resize(255),\n",
    "                                            transforms.CenterCrop(224),\n",
    "                                            transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                            transforms.RandomRotation(15),\n",
    "                                            transforms.RandomGrayscale(p=1),\n",
    "                                            transforms.RandomAffine(translate=(0.08,0.1), degrees=15),\n",
    "                                            transforms.ToTensor()\n",
    "                                           ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c03eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1341\n",
      "1193\n"
     ]
    }
   ],
   "source": [
    "path = \"./chest_xray/chest_xray\"\n",
    "\n",
    "dataset1 = datasets.ImageFolder(path+'/train', \n",
    "                      transform=transformer['dataset1'])\n",
    "\n",
    "dataset2 = datasets.ImageFolder(path+'/train', \n",
    "                      transform=transformer['dataset2'])\n",
    "\n",
    "dataset3 = datasets.ImageFolder(path+'/train', \n",
    "                      transform=transformer['dataset3'])\n",
    "\n",
    "test_size1 = int(3875/(1341+3875) * len(dataset2))\n",
    "train_size1 = len(dataset2) - test_size1\n",
    "\n",
    "test_size2 = int(4023/(1341+3875) * len(dataset3))\n",
    "train_size2 = len(dataset3) - test_size2\n",
    "\n",
    "norm1, _ = torch.utils.data.random_split(dataset2, [train_size1, test_size1])\n",
    "norm2, _ = torch.utils.data.random_split(dataset3, [train_size2, test_size2])\n",
    "\n",
    "print(len(norm1))\n",
    "print(len(norm2))\n",
    "\n",
    "# norm1, _ = train_test_split(dataset2, test_size= 3875/(1341+3875), shuffle=False)\n",
    "# norm2, _ = train_test_split(dataset3, test_size= 4023/(1341+3875), shuffle=False)\n",
    "\n",
    "# print(len(norm1))\n",
    "# print(len(norm2))\n",
    "\n",
    "dataset = ConcatDataset([dataset1, norm1, norm2])\n",
    "trainset = dataset\n",
    "\n",
    "#trainset = datasets.ImageFolder(os.path.join(path, 'train'),transform = train_transforms)\n",
    "testset = datasets.ImageFolder(os.path.join(path, 'test'),transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed1cc781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "#class_names = trainset.classes\n",
    "#print(class_names)\n",
    "# print(trainset.class_to_idx)\n",
    "print(testset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539715b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7750\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset))\n",
    "print(len(testset))\n",
    "\n",
    "# train_set_size = 4000\n",
    "# valid_set_size = len(trainset) - train_set_size\n",
    "# trainset, valid_set = torch.utils.data.random_split(trainset, [train_set_size, valid_set_size])\n",
    "\n",
    "# test_set_size = 600\n",
    "# valid_set_size = len(testset) - test_set_size\n",
    "# testset, valid_set = torch.utils.data.random_split(testset, [test_set_size, valid_set_size])\n",
    "\n",
    "# print(len(trainset))\n",
    "# print(len(testset))\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle= True, num_workers=4, pin_memory=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size= 50,\n",
    "                                         shuffle= False, num_workers=4, pin_memory=True)\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "179893ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, best_acc = 0.0):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        counter = 0\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            counter += 1\n",
    "            if counter % 100 == 99:    # print every 100 mini-batches\n",
    "              now = datetime.now()\n",
    "              current_time = now.strftime(\"%H:%M:%S\")\n",
    "              print(\"Current Time =\", current_time)\n",
    "              print(f\"Epoch: {epoch} Seen:{(counter+1)*10}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_loss = running_loss / len(trainloader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(trainloader.dataset)\n",
    "\n",
    "        print(f'Training Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "\n",
    "        model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        counter = 0\n",
    "        # Iterate over data.\n",
    "        print(\"~~~~Testing~~~~\")\n",
    "        for inputs, labels in testloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            counter += 1\n",
    "            if counter % 100 == 99:    # print every 100 mini-batches\n",
    "              now = datetime.now()\n",
    "              current_time = now.strftime(\"%H:%M:%S\")\n",
    "              print(\"Current Time =\", current_time)\n",
    "              print(f\"Epoch: {epoch} Seen:{(counter+1)*10}\")\n",
    "\n",
    "        epoch_loss = running_loss / len(testloader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(testloader.dataset)\n",
    "\n",
    "        print(f'Testing Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        # deep copy the model\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48e22ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Stan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#model_ft = models.vgg16_bn()\n",
    "\n",
    "model_ft = models.densenet161(pretrained=True)\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "in_features = model_ft.classifier.in_features\n",
    "\n",
    "model_ft.classifier = nn.Linear(in_features, 2)\n",
    "\n",
    "# model_ft = models.resnet18(pretrained=True)\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "# model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9b8967",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "Current Time = 17:40:33\n",
      "Epoch: 0 Seen:1000\n",
      "Training Loss: 0.2809 Acc: 0.8881\n",
      "~~~~Testing~~~~\n",
      "Testing Loss: 0.2870 Acc: 0.8798\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "Current Time = 17:42:12\n",
      "Epoch: 1 Seen:1000\n",
      "Training Loss: 0.1625 Acc: 0.9453\n",
      "~~~~Testing~~~~\n",
      "Testing Loss: 0.2834 Acc: 0.8846\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "Current Time = 17:43:44\n",
      "Epoch: 2 Seen:1000\n",
      "Training Loss: 0.1423 Acc: 0.9486\n",
      "~~~~Testing~~~~\n",
      "Testing Loss: 0.2898 Acc: 0.8862\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "Current Time = 17:45:20\n",
      "Epoch: 3 Seen:1000\n",
      "Training Loss: 0.1331 Acc: 0.9535\n",
      "~~~~Testing~~~~\n",
      "Testing Loss: 0.2968 Acc: 0.8862\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "Current Time = 17:46:57\n",
      "Epoch: 4 Seen:1000\n",
      "Training Loss: 0.1356 Acc: 0.9526\n",
      "~~~~Testing~~~~\n",
      "Testing Loss: 0.2901 Acc: 0.8894\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "Current Time = 17:48:30\n",
      "Epoch: 5 Seen:1000\n",
      "Training Loss: 0.1348 Acc: 0.9529\n",
      "~~~~Testing~~~~\n",
      "Testing Loss: 0.3067 Acc: 0.8846\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "Current Time = 17:50:03\n",
      "Epoch: 6 Seen:1000\n",
      "Training Loss: 0.1334 Acc: 0.9523\n",
      "~~~~Testing~~~~\n",
      "Testing Loss: 0.2986 Acc: 0.8878\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "Current Time = 17:51:38\n",
      "Epoch: 7 Seen:1000\n",
      "Training Loss: 0.1340 Acc: 0.9515\n",
      "~~~~Testing~~~~\n",
      "Testing Loss: 0.3018 Acc: 0.8846\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "Current Time = 17:53:13\n",
      "Epoch: 8 Seen:1000\n",
      "Training Loss: 0.1336 Acc: 0.9489\n",
      "~~~~Testing~~~~\n",
      "Testing Loss: 0.3059 Acc: 0.8830\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "Current Time = 17:54:45\n",
      "Epoch: 9 Seen:1000\n",
      "Training Loss: 0.1360 Acc: 0.9486\n",
      "~~~~Testing~~~~\n",
      "Testing Loss: 0.2957 Acc: 0.8846\n",
      "\n",
      "Training complete in 15m 56s\n",
      "Best val Acc: 0.889423\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=10, best_acc = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a000a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './testrresnetmymodel.pt'\n",
    "torch.save(model_ft.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93672311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = './testresnetmymodel.pt'\n",
    "# net = Net()\n",
    "# net.load_state_dict(torch.load(save_path))  \n",
    "# net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8efb623",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimages = []\n",
    "testlabels = []\n",
    "for image, label in testset:\n",
    "    testimages.append(image.numpy())\n",
    "    testlabels.append(label)\n",
    "    \n",
    "#print(testimages[0])\n",
    "testimages = np.array(testimages, dtype=np.float32)\n",
    "#print(testimages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2d19db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class AttackDataset(Dataset):\n",
    "    def __init__(self, attack_images, attack_labels,  transforms=None):\n",
    "        self.attack_images = attack_images\n",
    "        self.attack_labels = attack_labels\n",
    "        self.transforms = transforms\n",
    "        self.data_len = len(attack_images)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.attack_images[idx]\n",
    "        #print(np.shape(image))\n",
    "        label = self.attack_labels[idx]\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "227dc40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "end\n",
      "start2\n",
      "end2\n"
     ]
    }
   ],
   "source": [
    "print(\"starting\")\n",
    "\n",
    "converted_testimages = []\n",
    "\n",
    "for i in range(0, len(testimages)):\n",
    "    #print(np.shape(testimages[i]))\n",
    "    convert = testimages[i].transpose(1,2,0)\n",
    "    #print(np.shape(convert))\n",
    "    converted_testimages.append(convert)\n",
    "    \n",
    "    \n",
    "test_transforms2 = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "attack_trainset = ConcatDataset([trainset, AttackDataset(converted_testimages,testlabels, test_transforms2)])\n",
    "batch_size = 10\n",
    "print(\"end\")\n",
    "attack_trainloader = torch.utils.data.DataLoader(attack_trainset, batch_size=batch_size,\n",
    "                                          shuffle= True, num_workers=0)\n",
    "print(\"start2\")\n",
    "dataiter = iter(attack_trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(\"end2\")\n",
    "for i in range(1):\n",
    "  #print(images[i].shape, labels[i])\n",
    "    transform = transforms.ToPILImage()\n",
    "    img = transform(images[i+2])\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32446f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
